{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 什么是机器学习？\n",
    "\n",
    "* 机器学习是让计算机具有学习的能力，无需进行明确编程。—— 亚瑟·萨缪尔，1959\n",
    "* 计算机程序利用经验E 学习任务T，性能是P，如果针对任务T 的性能P 随着经验E 不断增长，则称为机器学习。—— 汤姆·米切尔，1997\n",
    "\n",
    "# 为什么使用机器学习？\n",
    "\n",
    "* 需要进行大量手工调整或需要拥有长串规则才能解决的问题：机器学习算法通常可以简化代码、提高性能。\n",
    "* 问题复杂，传统方法难以解决：最好的机器学习方法可以找到解决方案。\n",
    "* 环境有波动：机器学习算法可以适应新数据。\n",
    "* 洞察复杂问题和大量数据。\n",
    "\n",
    "# 机器学习系统的类型\n",
    "\n",
    "## 监督学习\n",
    "\n",
    "* 在监督学习中，用来训练算法的训练数据包含了答案，称为标签\n",
    "* 一些重要的监督学习算法\n",
    "    1. K近邻\n",
    "    2. 线性回归\n",
    "    3. 逻辑回归\n",
    "    4. SVM\n",
    "    5. 决策树\n",
    "    6. 随机森林\n",
    "    7. 神经网络\n",
    "\n",
    "## 半监督学习\n",
    "\n",
    "* 一些算法可以处理部分带标签的训练数据，通常是大量不带标签数据加上小部分带标签数据。这称作半监督学习\n",
    "* 多数半监督学习算法是非监督和监督算法的结合。例如：\n",
    "    1. 深度信念网络（deep belief networks）是基于被称为互相叠加的受限玻尔兹曼机（restricted Boltzmann machines，RBM）的非监督组件。RBM 是先用非监督方法进行训练，再用监督学习方法进行整个系统微调。\n",
    "\n",
    "## 非监督学习\n",
    "\n",
    "* 在非监督学习中，训练数据是没有加标签的\n",
    "* 一些重要的非监督学习算法\n",
    "    1. 聚类\n",
    "        1. K均值\n",
    "        2. 层次聚类分析\n",
    "        3. 期望最大值\n",
    "    2. 可视化和降维\n",
    "        1. 主成分分析\n",
    "        2. 核主成分分析\n",
    "        3. 局部线性嵌入\n",
    "        4. t-分布邻域嵌入算法\n",
    "    3. 关联性规则学习\n",
    "        1. Apriori算法\n",
    "        2. Eclat算法\n",
    "\n",
    "## 强化学习\n",
    "\n",
    "* 强化学习非常不同。学习系统在这里被称为智能体（agent），可以对环境进行观察，选择和执行动作，获得奖励（负奖励是惩罚）。然后它必须自己学习哪个是最佳方法（称为策略，policy），以得到长久的最大奖励。策略决定了智能体在给定情况下应该采取的行动。\n",
    "* 例如：\n",
    "    1. DeepMind 的AlphaGo \n",
    "\n",
    "## 批量学习\n",
    "\n",
    "* 离线（线下）学习\n",
    "* 对新数据需要重新学习\n",
    "\n",
    "\n",
    "## 在线学习\n",
    "\n",
    "* 流式计算\n",
    "* 动态学习\n",
    "* 如果坏数据被用来训练，系统性能会逐渐下滑\n",
    "\n",
    "\n",
    "## 基于实例学习\n",
    "\n",
    "* 记忆学习\n",
    "* 系统先用记忆学习案例，然后使用相似度测量推广到新的例子\n",
    "\n",
    "## 基于模型学习\n",
    "\n",
    "* 从样本集进行归纳的方法是建立这些样本的模型，然后使用这个模型进行预测\n",
    "\n",
    "# 机器学习的主要挑战\n",
    "\n",
    "1. 训练样本量不足\n",
    "    * 即便对于非常简单的问题，一般也需要数千的样本，\n",
    "    * 对于复杂的问题，比如图像或语音识别，你可能需要数百万的样本（除非你能重复使用部分存在的模型）\n",
    "2. 没有代表性的训练数据\n",
    "    * 样本太小，有噪声\n",
    "    * 样本大，也有没有代表性的数据，取样错误，就会样本偏差\n",
    "3. 低质量数据\n",
    "    * 明显异常值，删掉\n",
    "    * 如果一些实例缺少特征（比如，你的5% 的顾客没有说明年龄），你必须决定是否忽略这个属性、忽略这些实例、填入缺失值（比如，年龄中位数），或者训练一个含有这个特征的模型和一个不含有这个特征的模型，等等。\n",
    "4. 不相关的特征\n",
    "    * 特征工程\n",
    "        1. 特征选择\n",
    "        2. 特征提取：组合特征等\n",
    "        3. 手机新数据创建新特征\n",
    "5. 过拟合训练数据\n",
    "    * 简化模型\n",
    "    * 收集更多训练数据\n",
    "    * 减小训练数据噪声\n",
    "6. 欠拟合训练数据\n",
    "    * 选择一个更强大的模型，带有更多参数\n",
    "    * 用更好的特征训练学习算法（特征工程）\n",
    "    * 减小对模型的限制（比如，减小正则化参数）\n",
    "\n",
    "# 测试与确认\n",
    "\n",
    "* 训练集、验证集、测试集\n",
    "* 一般使用80% 的数据进行训练，保留20%用于测试。\n",
    "* 为了避免“浪费”过多训练数据在验证集上，通常的办法是使用交叉验证：训练集分成互补的子集，每个模型用不同的子集训练，再用剩下的子集验证。一旦确定模型类型和超参数，最终的模型使用这些超参数和全部的训练集进行训练，用测试集得到推广误差率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
